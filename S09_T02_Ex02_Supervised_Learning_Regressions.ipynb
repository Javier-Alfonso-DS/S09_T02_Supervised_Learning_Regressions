{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [Level 3](#)\n",
    "\n",
    "## Exercise 6 - Do not use the DepDelay variable when making predictions.\n",
    "\n",
    "This is going to be the second execution of the whole notebook but without the DepDelay variable.  \n",
    "So we will see exactly the effect of taking off this very dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Level 1](#)\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "Create at least three different regression models to try to predict as well as possible the flight delay (ArrDelay) of DelayedFlights.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings to display all columns (default is 20, now is None (all))\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned and sampled train an test dataset from previous Task.\n",
    "df_train = pd.read_csv('..\\data\\DelayedFlights_train.csv')\n",
    "df_test  = pd.read_csv('..\\data\\DelayedFlights_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Train / Test Sample \n",
    "* Is imported from previous Task (S09T01).  \n",
    "* Is 1% of the original dataset, randomly sampled and stratified by Airline.\n",
    "* Is parted 33% test and 66% train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's delete the first column\n",
    "df_train = df_train.drop(columns='Unnamed: 0')\n",
    "df_test  = df_test.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletion of DepDelay attribute \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's delete the first column\n",
    "df_train = df_train.drop(columns='DepDelay')\n",
    "df_test  = df_test.drop(columns='DepDelay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st model: Linear regression between DepDelay and ArrDelay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 1:  \n",
    "Is Not Applicable (N/A) now without DepDelay attribute.  \n",
    "Let's remember from previous execution the conclusions of the Linear regression with DepDelay:  \n",
    "* The accuracy of the model was very high (0.895 with train data and 0.902 with test data).  \n",
    "* The dependency between Arrival Delay and Departure Delay is quite obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd model: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Y or Target is ArrDelay:\n",
    "y_train = df_train.ArrDelay\n",
    "y_train = y_train.array # Convert pandas series to numpy array\n",
    "type(y_train)\n",
    "y_test  = df_test.ArrDelay.array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our X now is going to be all the columns in df_train except ArrDelay and Date (also the OHE of Airline)\n",
    "X_train = df_train.drop(columns=[\"ArrDelay\",\"Date\"])\n",
    "feature_list = list(X_train.columns) # Saving feature names for later use\n",
    "X_train = X_train.to_numpy() # Convert dataframe to array\n",
    "type(X_train)\n",
    "X_test = df_test.drop(columns=[\"ArrDelay\",\"Date\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model ( calculate b0...bn for the multiple lineal model y = b0 + b1x1 +... + bnxn)\n",
    "model2 = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.206\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train2 = model2.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with test data: -97068975798565535744.000\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with test data.\n",
    "r_sq_test2 = model2.score(X_test,y_test)\n",
    "print('coefficient of determination with test data: %.3f' %r_sq_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression:\n",
      " Accuracy with train data: 0.19984159117574923 +/- 0.03683768952188743 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with train data\n",
    "accuracies2a = cross_val_score(estimator = model2, X=X_train, y=y_train , cv = 10)\n",
    "print(\"Multiple Linear Regression:\\n Accuracy with train data:\", accuracies2a.mean(), \"+/-\", accuracies2a.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression:\n",
      " Accuracy with test data: 0.20230081003217393 +/- 0.08631821596875758 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with test data\n",
    "accuracies2b = cross_val_score(estimator = model2, X=X_test, y=y_test , cv = 10)\n",
    "print(\"Multiple Linear Regression:\\n Accuracy with test data:\", accuracies2b.mean(), \"+/-\", accuracies2b.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12919,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the prediction of the model\n",
    "y_pred2 = model2.predict(X_train)\n",
    "y_pred2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 2:  \n",
    "The accuracy of the model $R^2$ with train data is very low (0.206).   \n",
    "The accuracy of the model $R^2$ with test data is very bad (-97068975798565535744). A negative number means that the model is arbitrarily worse.   \n",
    "That is a very bad model, meaning that all the data was explained with the DepDelay variable. \n",
    "\n",
    "We also apply the k-Fold Cross Validation with train data and test data, and the results are low, but not so bad (train:0.19, test:0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd model: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create the model of Random Forest\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 100 decision trees\n",
    "model3 = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.986\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train3 = model3.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with test data: 0.927\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with test data.\n",
    "r_sq_test3 = model3.score(X_test,y_test)\n",
    "print('coefficient of determination with test data: %.3f' %r_sq_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Regression:\n",
      " Accuracy: 0.927 +/- 0.018 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with train data (we could/should do it with all the data - this will be done on Exercise 4)\n",
    "accuracies3a = cross_val_score(estimator = model3, X=X_train, y=y_train , cv = 10)\n",
    "print(\"RandomForest Regression:\\n Accuracy: %.3f\"%accuracies3a.mean(),\"+/- %.3f\"%accuracies3a.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Regression:\n",
      " Accuracy: 0.865 +/- 0.059 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with test data\n",
    "accuracies3b = cross_val_score(estimator = model3, X=X_test, y=y_test , cv = 10)\n",
    "print(\"RandomForest Regression:\\n Accuracy: %.3f\"%accuracies3b.mean(),\"+/- %.3f\"%accuracies3b.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12919,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the prediction of the model\n",
    "y_pred3 = model3.predict(X_train)\n",
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 3.\n",
    "* Now we can really know if the random forest regression model is good or not!\n",
    "* And the answer is that is very good! With test data, the $R^2$ is 0.927 and the accuracy of the Cross Validation is quite good (0.865 +/- 0.059).\n",
    "* The explanation now is that, even without the DepDelay variable, the random forest model can predict test data with good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th model: Neural Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "model4 = MLPRegressor(activation='relu',solver='adam',random_state=1, max_iter=500)\n",
    "model4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with test data: 0.951\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with test data. \n",
    "r_sq_test4 = model4.score(X_test,y_test)\n",
    "print('coefficient of determination with test data: %.3f' %r_sq_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Regression:\n",
      " Accuracy: 0.951 +/- 0.013 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with train data (we could/should do it with all the data - this will be done on Exercise 4)\n",
    "accuracies4a = cross_val_score(estimator = model4, X=X_train, y=y_train , cv = 10)\n",
    "print(\"Neural Network Regression:\\n Accuracy: %.3f\"%accuracies4a.mean(),\"+/- %.3f\"%accuracies4a.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Regression:\n",
      " Accuracy: 0.938 +/- 0.037 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with test data (we could/should do it with all the data - this will be done on Exercise 4)\n",
    "accuracies4b = cross_val_score(estimator = model4, X=X_test, y=y_test , cv = 10)\n",
    "print(\"Neural Network Regression:\\n Accuracy: %.3f\"%accuracies4b.mean(),\"+/- %.3f\"%accuracies4b.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12919,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the prediction of the model\n",
    "y_pred4 = model4.predict(X_train)\n",
    "y_pred4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 4.\n",
    "* Again, now we can really know if the neural network regression model is good or not!\n",
    "* And the answer is that is very good! With test data, the $R^2$ is 0.951 and the accuracy of the Cross Validation is quite good (0.938 +/- 0.037).\n",
    "* The explanation now is that, even without the DepDelay variable, the random forest model can predict test data with good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Compare them on the basis of MSE and R2 .\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 has been calculated before, we copy here the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Multiple Linear Regression Model------------\n",
      "R^2 - coefficient of determination with train data: 0.206\n",
      "R^2 - coefficient of determination with test data: -97068975798565535744.000\n",
      "--------------Random Forest Regression Model------------\n",
      "R^2 - coefficient of determination with train data: 0.986\n",
      "R^2 - coefficient of determination with test data: 0.927\n",
      "-------Neural Network Regression Model------------\n",
      "R^2 - coefficient of determination with train data: 0.974\n",
      "R^2 - coefficient of determination with test data: 0.951\n"
     ]
    }
   ],
   "source": [
    "print(\"-------Multiple Linear Regression Model------------\")\n",
    "print('R^2 - coefficient of determination with train data: %.3f' %r_sq_train2)\n",
    "print('R^2 - coefficient of determination with test data: %.3f' %r_sq_test2)\n",
    "print(\"--------------Random Forest Regression Model------------\")\n",
    "print('R^2 - coefficient of determination with train data: %.3f' %r_sq_train3)\n",
    "print('R^2 - coefficient of determination with test data: %.3f' %r_sq_test3)\n",
    "print(\"-------Neural Network Regression Model------------\")\n",
    "print('R^2 - coefficient of determination with train data: %.3f' %r_sq_train4)\n",
    "print('R^2 - coefficient of determination with test data: %.3f' %r_sq_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 5.\n",
    "* Now, we see that Multiple Linear Regression Model is not a good model for this dataset.\n",
    "* But, Random forest is a good one (0.927) and Neural Network even better (0.951).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE has not been calculated, we calculate it now and print here the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Multiple Linear Regression Model------------\n",
      "MSE - Mean Square Error with train data: 0.794\n",
      "--------Random Forest Regression Model------------\n",
      "MSE - Mean Square Error with train data: 0.014\n",
      "-------Neural Network Regression Model------------\n",
      "MSE - Mean Square Error with train data: 0.026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"-------Multiple Linear Regression Model------------\")\n",
    "print('MSE - Mean Square Error with train data: %.3f' %mean_squared_error(y_train,y_pred2))\n",
    "print(\"--------Random Forest Regression Model------------\")\n",
    "print('MSE - Mean Square Error with train data: %.3f' %mean_squared_error(y_train,y_pred3))\n",
    "print(\"-------Neural Network Regression Model------------\")\n",
    "print('MSE - Mean Square Error with train data: %.3f' %mean_squared_error(y_train,y_pred4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 6.\n",
    "* Again, we see that Mean Square error with train data is higher. (0.794) (not bad, by the way)\n",
    "* Random forest is the best one (0.014)\n",
    "* Neural Network is the second, but near to the first (0.026)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Train them using the different parameters they allow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.- Multiple Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.206\n"
     ]
    }
   ],
   "source": [
    "# This is our original model:\n",
    "# Fit the model ( calculate b0...bn for the multiple lineal model y = b0 + b1x1 +... + bnxn)\n",
    "model2 = LinearRegression().fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train2 = model2.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.206\n"
     ]
    }
   ],
   "source": [
    "# Let's now use different parameters: \n",
    "model2 = LinearRegression(fit_intercept=False).fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train2 = model2.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train2)\n",
    "\n",
    "# We don't change normalize= because is going to be deprecated and we have normalized before.\n",
    "# copy_X will only change if we want to change X or not. By default is copied (not changed), if we use False, X will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.206\n"
     ]
    }
   ],
   "source": [
    "# n_jobs: number of jobs to use for the computation. By default is None, interpreted usually as 1 CPU.\n",
    "# if we use -1 all CPUs will be used in Parallel. Only effective with large datasets. Right now our \n",
    "# computational time for this model is 0.1, no improvement expected.\n",
    "model2 = LinearRegression(n_jobs=-1).fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train2 = model2.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation 7.  \n",
    "* No improvement / change with the parameters used, speed is the same (0.1s) and $R^2$ is the same (0.206)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.- Random Forest Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.991\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 100 decision trees\n",
    "model3 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_train, y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train3 = model3.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.986\n"
     ]
    }
   ],
   "source": [
    "# Let's change parameters, but with R2 of 0.991 and speed 12.3s is going to be difficult to see differences.\n",
    "\n",
    "# The most important parameter is n_estimators, how many \"trees\" are in the forest. \n",
    "# By default is 100, let's change it to 10\n",
    "model3 = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_train, y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train3 = model3.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.969\n"
     ]
    }
   ],
   "source": [
    "# The speed has improved to 1.5s and R2 is still very high 0.986. \n",
    "# If we change it to 1000 trees, R2 is the same, but time is 15h.\n",
    "\n",
    "# criterion parameter also changes the function to measure the quality of a split.\n",
    "# By default is squared_error, let's change it to absolute_error (poisson is not possible because there are negative values on y array)\n",
    "model3 = RandomForestRegressor(n_estimators = 10, criterion='absolute_error', random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_train, y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train3 = model3.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.969\n"
     ]
    }
   ],
   "source": [
    "# There are many more parameters to change, let's just make a last change, in order to try to improve the speed, lets compute again \n",
    "# the previous model, but with using all CPUs in parallel.\n",
    "model3 = RandomForestRegressor(n_estimators = 10, criterion='absolute_error', n_jobs= -1, random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_train, y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train3 = model3.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation 8.  \n",
    "* The speed has effectively improved with n_jobs = -1, from 70s to 20s. Remark that CPU Performance goes to 100%!\n",
    "* $R^2$ with default parameters was 0.991, changing the parameters the accuracy goes down a little bit (0.986 and 0.969)\n",
    "* See comments in code, we have changed the numbers of trees, affecting to the calculation speed of the model. \n",
    "* Also criterion was changed, but with not very different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.- Neural Network Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model4 = MLPRegressor(activation='relu',solver='adam',random_state=1, max_iter=500)\n",
    "model4.fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.981\n"
     ]
    }
   ],
   "source": [
    "# Let's increase to 5 times default number of hidden layers\n",
    "model4 = MLPRegressor(hidden_layer_sizes=(500,), activation='relu',solver='adam',random_state=1, max_iter=500)\n",
    "model4.fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Let's change the activation to logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)). (old school)\n",
    "model4 = MLPRegressor(activation='logistic',solver='adam',random_state=1, max_iter=500)\n",
    "model4.fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with train data: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalor\\anaconda3\\envs\\ITAcademy\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Let's increase to change the solver to lbfgs (optimizer in the family of quasi-Newton methods)\n",
    "model4 = MLPRegressor(activation='relu',solver='lbfgs',random_state=1, max_iter=1000)\n",
    "model4.fit(X_train,y_train)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_train,y_train)\n",
    "print('coefficient of determination with train data: %.3f' %r_sq_train4)\n",
    "\n",
    "        # Note: The default solver 'adam' works pretty well on relatively\n",
    "        # large datasets (with thousands of training samples or more) in terms of\n",
    "        # both training time and validation score.\n",
    "        # For small datasets, however, 'lbfgs' can converge faster and perform\n",
    "        # better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation 9.\n",
    "* The initial R^2 is 0.974. \n",
    "* When we increase the hidden layers from 100 to 500, we get a better $R^2$ (0.981).  \n",
    "* If we change the relu function to the logistic sigmoid function, it decrease slightly to 0.972, and is significantly slower (20s to 10s (double))\n",
    "* If we change the solver from adam to lbfgs, we have to increase the max_iters, the $R^2$ goes up (0.992), but it doesn't converge after ~6min and 10000 iters.  \n",
    "\n",
    "Error message: \n",
    "![](2022-03-14-17-15-14.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Compare their performance using the test/train approach or using all data (internal validation).\n",
    "\n",
    "Previously, we have used the test/train approach. Let's now use all data (internal validation) and check if R^2 changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.- Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19283, 33)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's concatenate df_train & df_test\n",
    "df_complete = pd.concat([df_train,df_test])\n",
    "df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All samples have been combined.\n",
    "# Now let's create the models with all data now and test R^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.arrays.numpy_.PandasArray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Y or Target is ArrDelay:\n",
    "y_complete = df_complete.ArrDelay\n",
    "y_complete = y_complete.array # Convert pandas series to numpy array\n",
    "type(y_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our X now is going to be all the columns in df_complete except ArrDelay and Date (also the OHE of Airline)\n",
    "X_complete = df_complete.drop(columns=[\"ArrDelay\",\"Date\"])\n",
    "feature_list = list(X_complete.columns) # Saving feature names for later use\n",
    "X_complete = X_complete.to_numpy() # Convert dataframe to array\n",
    "type(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's test our last 3 models\n",
    "# Fit the model ( calculate b0...bn for the multiple lineal model y = b0 + b1x1 +... + bnxn)\n",
    "model2 = LinearRegression().fit(X_complete,y_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with all data: 0.209\n"
     ]
    }
   ],
   "source": [
    "# Calculate R2 to see the accuracy of the model with complete data.\n",
    "r_sq_complete2 = model2.score(X_complete,y_complete)\n",
    "print('coefficient of determination with all data: %.3f' %r_sq_complete2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression:\n",
      " Accuracy with train data: 0.204 +/-   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with all data\n",
    "accuracies2 = cross_val_score(estimator = model2, X=X_complete, y=y_complete, cv = 10) # default cv = 5\n",
    "print(\"Multiple Linear Regression:\\n Accuracy with train data: %.3f\"%accuracies2.mean(), \"+/- %3.f\"%accuracies2.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.- Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with all data: 0.993\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 100 decision trees\n",
    "model3 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "# Train the model on training data\n",
    "model3.fit(X_complete, y_complete)\n",
    "# Calculate R2 to see the accuracy of the model with all data.\n",
    "r_sq_train3 = model3.score(X_complete,y_complete)\n",
    "print('coefficient of determination with all data: %.3f' %r_sq_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression:\n",
      " Accuracy with train data: 0.948 +/-   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with all data\n",
    "accuracies3 = cross_val_score(estimator = model3, X=X_complete, y=y_complete , cv = 10) # default\n",
    "print(\"Random Forest Regression:\\n Accuracy with train data: %.3f\"%accuracies3.mean(), \"+/- %3.f\"%accuracies3.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.- Neural Network Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination with all data: 0.976\n"
     ]
    }
   ],
   "source": [
    "model4 = MLPRegressor(activation='relu',solver='adam',random_state=1, max_iter=500)\n",
    "model4.fit(X_complete,y_complete)\n",
    "# Calculate R2 to see the accuracy of the model with train data.\n",
    "r_sq_train4 = model4.score(X_complete,y_complete)\n",
    "print('coefficient of determination with all data: %.3f' %r_sq_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Regression:\n",
      " Accuracy with train data: 0.957 +/-   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (CV) with all data\n",
    "accuracies4 = cross_val_score(estimator = model4, X=X_complete, y=y_complete , cv = 10) # default\n",
    "print(\"Neural Network Regression:\\n Accuracy with train data: %.3f\"%accuracies4.mean(), \"+/- %3.f\"%accuracies4.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results with all data:\n",
    "* Multiple Linear Regression $R^2$ = 0.209\n",
    "* Random Forest Regression $R^2$ = 0.993\n",
    "* Neural Network Regression $R^2$ = 0.976\n",
    "\n",
    "These are the results of train/test approach:\n",
    "* Multiple Linear Regression $R^2$ = -97068975798565535744\n",
    "* Random Forest Regression $R^2$ = 0.927\n",
    "* Neural Network Regression $R^2$ = 0.951\n",
    "\n",
    "Now, the cross validation, with all the data, is more meaningful. Accuracy with different models are:\n",
    "* Multiple Linear Regression  = 0.204 +/-   0\n",
    "* Random Forest Regression = 0.948 +/-   0 \n",
    "* Neural Network Regression  = 0.957 +/-   0\n",
    "\n",
    "The result are the following:\n",
    "* All data, $R^2$ ➡️ Best model is Random Forest\n",
    "* Train/test approach, $R^2$ ➡️ Best model is Neural Network\n",
    "* All data, $CV$ ➡️ Best model is Neural Network\n",
    "* Train/test approach, $CV$ ➡️ Best model is Neural Network too (0.938 +/- 0.037)\n",
    "\n",
    "As conclusion, it seems that **the best model is Neural Network and the best tester for accuracy is All data with $CV$**."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "494e690407c5c7c9b2fbc0a1227ada2e3d821eefed538763ba3356ad470e06f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
